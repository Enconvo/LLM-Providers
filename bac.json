[
  {
    "name": "premai",
    "title": "Prem AI",
    "description": "Chat using [PremAI](https://www.premai.io/) which provide LLM service",
    "icon": "premai.png",
    "mode": "llm",
    "preferences": [
      {
        "name": "model",
        "description": "The model to generate the completion.",
        "type": "dropdown",
        "required": false,
        "title": "Model Name",
        "default": "gpt-3.5-turbo",
        "dataProxy": "llm|premai_models"
      },
      {
        "name": "apiKey",
        "description": "How to get api key? [ðŸ”‘here](https://www.premai.io/)",
        "type": "password",
        "required": false,
        "title": "API Key",
        "default": "",
        "defaultProxy": "KEY_PREMAI_APIKEY",
        "placeholder": "API Key"
      },
      {
        "name": "project_id",
        "description": "",
        "type": "number",
        "required": false,
        "title": "Project ID",
        "default": "",
        "defaultProxy": "KEY_PREMAI_PROJECT_ID",
        "placeholder": "Project ID"
      },
      {
        "name": "temperature",
        "description": "What sampling temperature to use. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.",
        "type": "dropdown",
        "required": false,
        "title": "Temperature",
        "default": "1.0",
        "data": [
          {
            "title": "none",
            "value": "0.0"
          },
          {
            "title": "low",
            "value": "0.5"
          },
          {
            "title": "medium",
            "value": "1.0"
          },
          {
            "title": "high",
            "value": "1.5"
          },
          {
            "title": "maximum",
            "value": "2.0"
          }
        ]
      },
      {
        "name": "streaming",
        "description": "Whether to stream output",
        "type": "checkbox",
        "required": false,
        "title": "Streaming",
        "default": true,
        "label": "Streaming",
        "visibility": "hidden"
      }
    ]
  },
  {
    "name": "chat_yii",
    "title": "Yi",
    "description": "Chat with Yi , learn more : [Yi developers](https://platform.lingyiwanwu.com/)",
    "icon": "yi.png",
    "mode": "no-view",
    "commandType": "provider",
    "preferences": [
      {
        "name": "credentials",
        "description": "The key management provider to use",
        "type": "extension",
        "required": false,
        "default": "yii",
        "extensionType": "credentials-provider",
        "extensionFilter": {
          "targetCommands": ["credentials|yii"]
        },
        "title": "Credential Provider"
      },
      {
        "name": "modelName",
        "description": "The model to generate the completion.",
        "type": "dropdown",
        "required": false,
        "title": "Model Name",
        "default": "yi-34b-chat-0205",
        "data": [
          {
            "title": "yi-large",
            "value": "yi-large",
            "context": 4000,
            "inputPrice": 0.0005,
            "outputPrice": 0.0015,
            "maxTokens": 3000
          },
          {
            "title": "yi-medium",
            "value": "yi-medium",
            "context": 4000,
            "inputPrice": 0.0005,
            "outputPrice": 0.0015,
            "maxTokens": 3000
          },
          {
            "title": "yi-vision",
            "value": "yi-vision",
            "context": 4000,
            "inputPrice": 0.0005,
            "outputPrice": 0.0015,
            "maxTokens": 3000
          },
          {
            "title": "yi-large-turbo",
            "value": "yi-large-turbo",
            "context": 4000,
            "inputPrice": 0.0005,
            "outputPrice": 0.0015,
            "maxTokens": 3000
          },
          {
            "title": "yi-34b-chat-0205",
            "value": "yi-34b-chat-0205",
            "context": 4000,
            "inputPrice": 0.0005,
            "outputPrice": 0.0015,
            "maxTokens": 3000
          },
          {
            "title": "yi-34b-chat-200k",
            "value": "yi-34b-chat-200k",
            "context": 200000,
            "inputPrice": 0.01,
            "outputPrice": 0.03,
            "maxTokens": 4000
          },
          {
            "title": "yi-vl-plus",
            "value": "yi-vl-plus",
            "context": 4000,
            "inputPrice": 0.01,
            "outputPrice": 0.03,
            "visionEnable": true,
            "maxTokens": 2000
          }
        ]
      },
      {
        "name": "temperature",
        "description": "What sampling temperature to use. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.",
        "type": "dropdown",
        "required": false,
        "title": "Temperature",
        "default": 1,
        "data": [
          {
            "title": "none",
            "value": 0
          },
          {
            "title": "low",
            "value": 0.5
          },
          {
            "title": "medium",
            "value": 1
          },
          {
            "title": "high",
            "value": 1.5
          },
          {
            "title": "maximum",
            "value": 2
          }
        ]
      }
    ]
  }
]
